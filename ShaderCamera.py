import cv2
import datetime # used for vhs tape filter timestamp
import matplotlib.pyplot as plt # used to display filtered video
import numpy as np
from picamera2 import Picamera2, Preview
from PIL import Image, ImageDraw, ImageFont # used for vhs tape filter and retro game filter
import skimage # used to add gaussian noise
import sys # used to read in desired filter from command line
import time # used for sleep funcionality
import random # used for retro game filter for scores

'''
Video Feed Filters
'''
# constants for all filters
video_size = (480, 640)
white = np.full(3, 255)
# create sobel filter
sobel_filter = np.zeros((3,3))
sobel_filter[0][0] = -1
sobel_filter[1][0] = -2
sobel_filter[2][0] = -1
sobel_filter[0][2] = 1
sobel_filter[1][2] = 2
sobel_filter[2][1] = 1
sobel_filter *= (1/8)

### WATERCOLOR FILTER ###
'''
NOTE:
The interpolant, generate_perlin_noise_2d, and 
generate_fractal_noise_2d functions are taken directly 
from the perlin_numpy github repo at: 
https://github.com/pvigier/perlin-numpy
Code is not our own
'''
def interpolant(t):
    return t*t*t*(t*(t*6 - 15) + 10)
def generate_perlin_noise_2d(
        shape, res, tileable=(False, False), interpolant=interpolant
):
    """Generate a 2D numpy array of perlin noise.

    Args:
        shape: The shape of the generated array (tuple of two ints).
            This must be a multple of res.
        res: The number of periods of noise to generate along each
            axis (tuple of two ints). Note shape must be a multiple of
            res.
        tileable: If the noise should be tileable along each axis
            (tuple of two bools). Defaults to (False, False).
        interpolant: The interpolation function, defaults to
            t*t*t*(t*(t*6 - 15) + 10).

    Returns:
        A numpy array of shape shape with the generated noise.

    Raises:
        ValueError: If shape is not a multiple of res.
    """
    delta = (res[0] / shape[0], res[1] / shape[1])
    d = (shape[0] // res[0], shape[1] // res[1])
    grid = np.mgrid[0:res[0]:delta[0], 0:res[1]:delta[1]]\
             .transpose(1, 2, 0) % 1
    # Gradients
    angles = 2*np.pi*np.random.rand(res[0]+1, res[1]+1)
    gradients = np.dstack((np.cos(angles), np.sin(angles)))
    if tileable[0]:
        gradients[-1,:] = gradients[0,:]
    if tileable[1]:
        gradients[:,-1] = gradients[:,0]
    gradients = gradients.repeat(d[0], 0).repeat(d[1], 1)
    g00 = gradients[    :-d[0],    :-d[1]]
    g10 = gradients[d[0]:     ,    :-d[1]]
    g01 = gradients[    :-d[0],d[1]:     ]
    g11 = gradients[d[0]:     ,d[1]:     ]
    # Ramps
    n00 = np.sum(np.dstack((grid[:,:,0]  , grid[:,:,1]  )) * g00, 2)
    n10 = np.sum(np.dstack((grid[:,:,0]-1, grid[:,:,1]  )) * g10, 2)
    n01 = np.sum(np.dstack((grid[:,:,0]  , grid[:,:,1]-1)) * g01, 2)
    n11 = np.sum(np.dstack((grid[:,:,0]-1, grid[:,:,1]-1)) * g11, 2)
    # Interpolation
    t = interpolant(grid)
    n0 = n00*(1-t[:,:,0]) + t[:,:,0]*n10
    n1 = n01*(1-t[:,:,0]) + t[:,:,0]*n11
    return np.sqrt(2)*((1-t[:,:,1])*n0 + t[:,:,1]*n1)
   
def generate_fractal_noise_2d(
        shape, res, octaves=1, persistence=0.5,
        lacunarity=2, tileable=(False, False),
        interpolant=interpolant
):
    """Generate a 2D numpy array of fractal noise.

    Args:
        shape: The shape of the generated array (tuple of two ints).
            This must be a multiple of lacunarity**(octaves-1)*res.
        res: The number of periods of noise to generate along each
            axis (tuple of two ints). Note shape must be a multiple of
            (lacunarity**(octaves-1)*res).
        octaves: The number of octaves in the noise. Defaults to 1.
        persistence: The scaling factor between two octaves.
        lacunarity: The frequency factor between two octaves.
        tileable: If the noise should be tileable along each axis
            (tuple of two bools). Defaults to (False, False).
        interpolant: The, interpolation function, defaults to
            t*t*t*(t*(t*6 - 15) + 10).

    Returns:
        A numpy array of fractal noise and of shape shape generated by
        combining several octaves of perlin noise.

    Raises:
        ValueError: If shape is not a multiple of
            (lacunarity**(octaves-1)*res).
    """
    noise = np.zeros(shape)
    frequency = 1
    amplitude = 1
    for _ in range(octaves):
        noise += amplitude * generate_perlin_noise_2d(
            shape, (frequency*res[0], frequency*res[1]), tileable, interpolant
        )
        frequency *= lacunarity
        amplitude *= persistence
    return noise

### WATERCOLOR FILTER ###
# setup constants for watercolor filter
edge_threshold = 0.99
edge_darkening_factor = 1.3
paper = generate_fractal_noise_2d((480, 640), (8, 8))
# remap paper values from [-1, 1] to [0, 1]
paper += 1
paper /= 2.0

# watercolor filter
def watercolor_filter(frame):
	# clip alpha channel
	frame = frame[:, :, 0:3]
	# convert to hsv to re-calculate saturation and value
	frame = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV).astype('float')
	h, s, v = cv2.split(frame)
	# Mimics how the ridges and valleys of paper effect saturation of
	# watercolor paints
	s *= paper
	
	# Edge Darkening effect
	outlines = cv2.filter2D(v.astype('float'), -1, \
			sobel_filter)
	v[outlines > edge_threshold] /= edge_darkening_factor
	v = cv2.GaussianBlur(v, (13, 13), -1) # blur to smooth the effect
	
	frame_out = cv2.merge([h, s, v])
	frame_out = cv2.cvtColor(frame_out.astype('uint8'), \
		cv2.COLOR_HSV2RGB)
	return frame_out

### CARTOON FILTER###
def cartoon_filter(frame):
	frame = frame[:,:,0:3]
	# Convert to grayscale and apply median blur to reduce image noise
	grayimg = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
	grayimg = cv2.medianBlur(grayimg, 5)
	# Get the edges
	edges = cv2.adaptiveThreshold(grayimg.astype(np.uint8), 255, \
		cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 5)
	# Convert to a cartoon version
	color = cv2.bilateralFilter(frame.astype(np.uint8), 9, 250, 250)
	cartoon = cv2.bitwise_and(color, color, mask=edges)
	return cartoon

### VHS TAPE FILTER ###
# Constants for vhs tape filter
font_size = 20
font_absolute_path = "/home/mreynold/raspberry-pi-shader-camera/fonts/VCR_OSD_MONO.ttf"
font = ImageFont.truetype(font_absolute_path, 20)
timestamp_x = 10
timestamp_y = video_size[0] - font_size - 10
timestamp_locaiton = (timestamp_x, timestamp_y)
# Add recording label
recording_label_text = "REC"
recording_dot_x = 10
recording_dot_y = 10

# Vhs tape filter
def vhs_filter(frame):
	# remove alpha channel
	frame = frame[:,:,0:3] 
	# convert image to np array (TODO see if needed now)
	np_image = np.array(frame)
	
	# Add scanlines: Skip every other line
	np_image[::2,:,:] = np_image[::2, :, :] * 0.3
	
	# Adjust color balance: Slightly increase red, decrease blue
	np_image[:,:,0] = np_image[:,:,0] * 1.1 # Red Channel
	np_image[:,:,2] = np_image[:, :, 2] * 0.9 # Blue Channel
	
	# Adding noise
	noise = np.random.normal(0, 25, np_image.shape)
	np_image = np.clip(np_image + noise, 0, 255)
	
	# Converting back to PIL Image
	vhs_image = Image.fromarray(np_image.astype('uint8'), 'RGB')
	
	# Adding timestamp
	draw = ImageDraw.Draw(vhs_image)

	# Formatting the timestamp text
	text = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
	
	# Positioning the text at the bottom left corner 
	# TODO move x and y out of the function
	draw.text(timestamp_locaiton, text, (255, 255, 255), font=font)
	
	# Add recording label
	# Drawing a red dot
	draw.ellipse([(recording_dot_x, recording_dot_y), \
		(recording_dot_x + 10, recording_dot_y + 10)], fill=(255, 0, 0))
	# Drawing the label text next to the red dot
	draw.text((recording_dot_x + 15, recording_dot_y - 5), \
		recording_label_text, (255, 255, 255), font=font)
	
	return vhs_image
	

### NIGHTVISION FILTER ###
# constants for nightvision filter
empty_channel = np.zeros(video_size, dtype=np.uint8)
green_intensity = 0.57 # value found experimentally
noise_variance = 0.0025 # value found experimentally

# nightvision filter
def nightvision_fx(frame):
	# make the input image green and black
	g_channel = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
	g_channel_reduced = (g_channel * green_intensity).astype(np.uint8)
	nightvision_frame = cv2.merge([empty_channel, g_channel_reduced, empty_channel])
	# add noise to the image to make it look grainy
	grainy_nightvision = skimage.util.random_noise(nightvision_frame, \
		mode='gaussian', var = noise_variance)
	return grainy_nightvision

### BLUEPRINT FILTER ###
# constants for blueprint filter
grid_size = 11 # value found experimentally
grid_strength = 0.4 # value found experimentally
blueprint_blue = (48, 48, 225) # value found experimentally
edge_threshold = 3.25 # value found experimentally

# create the blueprint grid
attenuated_white = grid_strength * white
blueprint_grid = np.full((video_size[0], video_size[1], 3), \
	blueprint_blue)
for i in range(0, blueprint_grid.shape[0]):
	for j in range(0, blueprint_grid.shape[1]):
		if (i % grid_size == 0 or j % grid_size == 0):
			blueprint_grid[i][j] = attenuated_white

# blueprint filter
def blueprint_fx(frame):
	frame = frame[:,:,0:3]
	# apply smoothing so we only get stronger edges
	blurred = cv2.GaussianBlur(frame, (3, 3), -1)
	# apply sobel filter to intensity image to get edges
	intensity_img = cv2.cvtColor(blurred, cv2.COLOR_RGB2GRAY)
	blueprint_outline = cv2.filter2D(intensity_img.astype('float'), -1, \
		sobel_filter)
	# threshold to only draw strong edges, edges drawn as white pixels
	blueprint_outline = np.abs(blueprint_outline)
	blueprint_outline[blueprint_outline > edge_threshold] = 255
	blueprint_outline[blueprint_outline != 255] = 0
	# make outline into rgb data
	mask = np.zeros(frame.shape)
	mask[:,:,0] = blueprint_outline
	mask[:,:,1] = blueprint_outline
	mask[:,:,2] = blueprint_outline
	# add edges ontop of blueprint grid
	bp_img = blueprint_grid + mask.astype('int')
	bp_img = np.clip(bp_img, 0, 255)
	return bp_img

### SKETCHBOOK FILTER ###
def sketchbook_filter(frame):
	frame = frame[:,:,0:3]
	# convert to grayscale
	grayscale = np.array(np.dot(frame[..., :3], [0.299, 0.587, 0.114]), \
		dtype = np.uint8)
	grayscale = np.stack((grayscale,) * 3, axis = -1)

	# invert the image
	invert_img = 255 - grayscale

	# blur the image
	blur_img = cv2.GaussianBlur(invert_img, ksize = (0, 0), sigmaX = 5)

	# create the sketchbook filter
	result = grayscale * 255.0 / (255.0 - blur_img)
	result[result > 255] = 255
	result[grayscale == 255] = 255
	result_img = result.astype('uint8')

	# sharpen the image
	kernel = np.array([[-1, -1, -1],
                      [-1, 9, -1],
                      [-1, -1, -1]])
    
	sharpenImage = cv2.filter2D(result_img, -1, kernel)

	return sharpenImage

### EMBOSSED FILTER ###
def embossed_filter(frame):
	frame = frame[:,:,0:3]
	kernel = np.array([[0, -3, -3],
                      [3, 0, -3],
                       [3, 3, 0]]) 
	emboss_img = cv2.filter2D(frame, -1, kernel = kernel)
	return emboss_img

### RETRO VIDEO GAME FILTER ###
# constants for retro video game filter
font_size_retro = 20
font_retro_path = "/home/mreynold/raspberry-pi-shader-camera/fonts/Gameplay.ttf"
font_retro = ImageFont.truetype(font_retro_path, 20)
coord_x = 10
coord_y = font_size + 10
score_locaiton = (10, coord_y)
score_num_location = (coord_x, coord_y*2)
level_location = (550, coord_y)
level_num_location = (550, coord_y*2)
lives_location = (coord_x, video_size[0] - font_size - 10)

# starting numbers for labels
score = 1
level = 1
life = 5

def retro_game_filter(frame):
	# convert image to np array
	np_image = np.array(frame)

	# get the height and width of the image
	height, width = np_image.shape[:2]

	# desired pixel size
	w, h = (150, 150)

	# Resize input to "pixelated" size
	temp = cv2.resize(np_image, (w, h), interpolation = cv2.INTER_LINEAR)

	# initialize the output image
	np_image = cv2.resize(temp, (width, height), interpolation = cv2.INTER_NEAREST)
	
	# Add scanlines: Skip every other line
	np_image[::2,:,:] = np_image[::2, :, :] * 0.3

	# converting image back to PIL image
	retro_image = Image.fromarray(np_image.astype('uint8'), 'RGB')

	# adding score, level, and lives labels
	draw = ImageDraw.Draw(retro_image)

	# labels
	score_text = "Score:"
	level_text = "Level:"
	life_text = "Lives: " + str(life)

	# logic to keep track of the lives, levels and score
	# score is more than 10 points then it resets to 0 and gain a level and life
	if score >= 10:
		level += 1
		life += 1
		score = 0
	# score is less than 0 lose a life and level
	elif score < 0:
		# level is under 0 it stays at 0
		if level <= 0:
			level = 0
			# all lives are lost level and score get reset to 0 and lives goes back up to 5
			if life <= 0:
				life = 5
				level = 0
				score = 0
			# subtract a life
			else:
				life -= 1
		# subtract a level and life
		else:
			level -= 1
			life -= 1
		# reset score back to 0
		score = 0

	# drawing the score	
	draw.text(score_locaiton, score_text, (255, 255, 255), font=font)
	draw.text(score_num_location, str(score), (255, 255, 255), font=font)
	
	# drawing the level
	draw.text(level_location, level_text, (255, 255, 255), font=font)
	draw.text(level_num_location, str(level), (255, 255, 255), font=font)

	# drawing the lifes 
	draw.text(lives_location, life_text, (255, 255, 255), font=font)

	# randomly generate a number between -3 and 3 to add to the score
	score = random.randint(-3, 3)
	score += score
	
	return retro_image

### NO FILTER ###
def no_filter(frame):
	return frame[:,:, 0:3]

'''
Video Input/Output Code
'''
watercolor_filter_code = "water"
cartoon_filter_code = "toon"
nightvision_filter_code = "night"
vhs_filter_code = "vhs"
blueprint_filter_code = "bp"
sketchbook_filter_code = "sketch"
embossed_filter_code = "emboss"
retro_game_filter_code = "retro"
no_filter_code = "none"

# set the video filter
def get_filter(filter_code):
	if (filter_code == cartoon_filter_code):
		return cartoon_filter
	elif (filter_code == nightvision_filter_code):
		return nightvision_fx
	elif (filter_code == blueprint_filter_code):
		return blueprint_fx
	elif (filter_code == vhs_filter_code):
		return vhs_filter
	elif (filter_code == sketchbook_filter_code):
		return sketchbook_filter
	elif (filter_code == embossed_filter_code):
		return embossed_filter
	elif (filter_code == watercolor_filter_code):
		return watercolor_filter
	elif (filter_code == retro_game_filter_code):
		return retro_game_filter
	elif(filter_code == no_filter_code):
		return no_filter
	else:
		print('''Usage: python3 ShaderCamera.py <filter code>. 
			Filter Codes: toon (cartoon filter), 
			night (nightvision filter), 
			bp (blueprint filter), 
			vhs (vhs filter), 
			sketch (sketch filter), 
			emboss (embossed filter), 
			water (watercolor filter),
			retro (retro game filter)''')
		exit(0)

index_of_filter = 1
video_filter = get_filter(sys.argv[index_of_filter])
# return the next frame (filtered)
def grab_frame():
	# get frame from the camera
	frame = picam.capture_array("main")
	# return filtered captured frame
	return video_filter(frame)
	
# Startup Camera
picam = Picamera2()
# Hide preview so that un-filtered video feed is not shown
picam.start(show_preview=False)
# give camera 3 seconds to startup
time.sleep(3)
	
# Display filtered video feed
# Note: below code is adapted from https://stackoverflow.com/questions/45025869/how-to-process-images-in-real-time-and-output-a-real-time-video-of-the-result
frame_plot = plt.imshow(grab_frame())
plt.ion()
while True:
	# display the latest filtered frame of the video
	frame_plot.set_data(grab_frame())
	# update display at roughly 30 fps
	plt.pause(0.03)